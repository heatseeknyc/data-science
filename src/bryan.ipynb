{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "#sensordata = pd.read_csv(sensorcsv)\n",
    "#userdata = pd.read_csv(usercsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = psycopg2.connect(database ='heatseek', user = 'heatseek', password = 'wearecoolsoweseekheat')\n",
    "    cursor = connection.cursor() #Open a cursor to perform operations\n",
    "    \n",
    "    cursor.execute('SELECT * from users LIMIT 100') #Executes the query\n",
    "    users = cursor.fetchall() #cursor.fetchone() for one line, fetchmany() for multiple lines, fetchall() for all lines\n",
    "    users = pd.DataFrame(users) #Saves 'users' as a pandas dataframe\n",
    "    users_header = [desc[0] for desc in cursor.description] #This gets the descriptions from cursor.description (names are in the 0th index)\n",
    "    users.columns = users_header #PD array's column names\n",
    "    \n",
    "    cursor.execute('SELECT * FROM readings LIMIT 1000;')\n",
    "    readings = cursor.fetchall()\n",
    "    readings = pd.DataFrame(readings)\n",
    "    readings_header = [desc[0] for desc in cursor.description]\n",
    "    readings.columns = readings_header\n",
    "    \n",
    "    cursor.execute('SELECT * FROM sensors LIMIT 100;')\n",
    "    sensors = cursor.fetchall()\n",
    "    sensors = pd.DataFrame(sensors)\n",
    "    sensors_header = [desc[0] for desc in cursor.description]\n",
    "    sensors.columns = sensors_header\n",
    "    \n",
    "    cursor.close() \n",
    "    connection.close()\n",
    "    \n",
    "except psycopg2.DatabaseError, error:\n",
    "    print 'Error %s' % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sensordata.user_id.unique()\n",
    "#sensordata.user_id.value_counts()\n",
    "#sensordata.violation.value_counts() #This returns the number of 't's and 'f's\n",
    "#np.sort(userdata.id.unique())\n",
    "#np.intersect1d(userdata.id.unique(), sensordata.user_id.unique()) #Returns the common ids in both the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#THIS HAS TO BE RUN ON CLEAN DATA THAT HAS REMOVED CASES WHERE SENSORS ARE POLLING FASTER THAN ONCE PER HOUR.\n",
    "\n",
    "#Function that takes (start date, end date, sensor id), returns % of failure\n",
    "\n",
    "def sensor_down(data, start_date, end_date, sensor_id=0):\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    sensor_readings = readings.loc[readings.sensor_id == sensor_id]\n",
    "    \n",
    "    #Converting to timestamps\n",
    "    for i in sensor_readings.index.values: #Iterates through all the index values\n",
    "        sensor_readings.loc[i, 'create_at'] = pd.Timestamp(sensor_readings.create_at[i])\n",
    "\n",
    "    #Using a boolean mask to select readings between the two dates \n",
    "    #(http://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates)   \n",
    "    mask = (sensor_readings['create_at'] > start_date) & (sensor_readings['create_at'] <= end_date)\n",
    "    sensor_readings = sensor_readings.loc[mask] #Get all readings between the two dates\n",
    "    \n",
    "    #We then calculate how many hours have passed for that specific sensor and date range\n",
    "    sensor_readings_start_date = sensor_readings.loc[sensor_readings.index.values[0], 'create_at']\n",
    "    sensor_readings_end_date = sensor_readings.loc[sensor_readings.index.values[len(sensor_readings)-1], 'create_at']\n",
    "    timedelta_in_seconds =  sensor_readings_end_date - sensor_readings_start_date #This returns Timedelta object\n",
    "    timedelta_in_seconds = timedelta_in_seconds.total_seconds()\n",
    "    total_number_of_hours = timedelta_in_seconds/3600\n",
    "    \n",
    "    proportion_of_uptime =len(sensor_readings)/total_number_of_hours\n",
    "    return proportion_of_uptime\n",
    "\n",
    "print sensor_down(readings, '2015-03-11', '2015-03-21', 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What criteria do we want to use.\n",
    "\n",
    "#SENSOR NUMBERS AS IDENTIFIERS, SOME DEGREE OF SEVERITY OF PROBLEM (CATEGORICAL)\n",
    "\n",
    "#for the criteria we go, how do we define \"bad\"\n",
    "#total days\n",
    "#proportion of days (or clusters?)\n",
    "#temperature discrepancy\n",
    "#multiple apartments in the same building (how many % of the apartments in a building and how bad)\n",
    "#multiple buildings by the same landlord (how many % of the buildings a landlord owns are bad)\n",
    "#are our sensors failing in a specific building?\n",
    "\n",
    "#Getting rid of test cases:\n",
    "#1. Can we just delete by test IDs?\n",
    "#2. If testing was separated by a minute, we can find all test cases by looping through all users,\n",
    "#  and if they have a bunch of data that was collected within minutes, delete the user?\n",
    "\n",
    "#We first convert the string dates into datetime format\n",
    "sensordata['formatteddate'] = sensordata.created_at.apply(lambda x: pd.to_datetime(x,  format = \"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "#Then, one way of telling if a user_id was an actual user or a test case was to calculate the average timedelta for each user_id.\n",
    "#Timedeltas of 1min are tests, 1 hour are users (don't know if this is always true, but if no user has an average polling rate\n",
    "#of 1 min, we can use a bunch of methods to filter away test cases step by step).\n",
    "\n",
    "sensordata['averagetimedelta'] = 0.00 #makes a new column\n",
    "\n",
    "for i in sensordata.user_id.unique(): #for each user\n",
    "    timelist = sensordata.loc[sensordata.user_id == i, 'formatteddate'] #this gives us a list of all their times in timestamp\n",
    "    timedeltas = [] \n",
    "    for j in range(1, len(timelist)-1):\n",
    "        timedeltas.append(timelist.iloc[j] - timelist.iloc[j-1]) #list of differences in time between time point j and j-1\n",
    "    try:\n",
    "        #we print the user_id, followd by their average time delta from point j to j-1\n",
    "        print i, abs(sum(timedeltas, datetime.timedelta(0)))/len(timedeltas) #the average timedelta\n",
    "    except ZeroDivisionError: #some cases have too few points (and results in a zero division error)\n",
    "        #instead of breaking with we encounter a zerodivisionerror, just print the following:\n",
    "        print i, \"Too few data points?\"\n",
    "    sensordata.loc[sensordata.user_id == i, 'averagetimedelta'] = averagetimedeltas.total_seconds()\n",
    "\n",
    "#3. If user ids are recycled, we'll have to do a combination of those things.\n",
    "\n",
    "#Some sensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Triage\n",
    "#We want to have a measure of which users are facing the most chronic problems.\n",
    "\n",
    "#Metric combining temperature difference and chronicity of problems\n",
    "\n",
    "#Write some code that subsets all the violation == 't' cases\n",
    "sensordataviolations = sensordata[sensordata.violation == 't'] #here it is.\n",
    "\n",
    "#Hackiest method: just number of violations/numberof nonviolations and sort users by that\n",
    "#That is, which users have had the most violations given the total number of readings \n",
    "\n",
    "violationsovertime = []\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    nonviolations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['f'] #Number of violations = 'f'\n",
    "    try:\n",
    "        violations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['t'] #Number of violations = 't'\n",
    "    except KeyError:\n",
    "        violations = 0    \n",
    "    sensordata.loc[sensordata.user_id == i, 'vfreq'] = float(violations)/float(nonviolations)\n",
    "    violationsovertime.append([i, (float(violations)/float(nonviolations))])\n",
    "\n",
    "#violations over time gives first the user_id, then the proportion of how many of their readings are violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stuff to do for fun\n",
    "\n",
    "#Variability/consistency\n",
    "#Which buildings have the least/most variable temperatures?\n",
    "#For this, we just calculate within-person variability (how much do sensor temperatures by the same user) vary as a function of time\n",
    "#We an use this same process to calculate variability between locations (e.g., just calculate variance for each location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, we loop over all unique users in the dataset and generate a measure of how long they've had the sensor running\n",
    "sensordata['totaltime'] = 0\n",
    "sensordata['vfreq'] = 0\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    firstentry = len(sensordata.loc[sensordata.user_id==i,'formatteddate']) #This gives us the index of the first timepoint\n",
    "    lasttime = sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[0] #This was the timestamp of the latest timepoint\n",
    "    firsttime =  sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[firstentry-1] #This was the timestamp of the first timepoint\n",
    "    sensordata.loc[sensordata.user_id == i, 'totaltime'] = lasttime - firsttime #This is the timedelta (over how long a period readings were made)\n",
    "    #print i, lasttime-firsttime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
