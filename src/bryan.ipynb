{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0) What: Test steps 1,2,3 in local Postgres instance\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#1) What: Create a second table(s) within Postgres. I suggest just adding \"_cleaned\" to the name and use the same prefix. \n",
    "#The schema will remain the same. William - any objections here? We don't have a dev/staging Postgres instance, do we? \n",
    "#Who: Jesse\n",
    "\n",
    "#2a) What: Take Bryan's new Python and test each 'rule,' adding logic for writing to Postgres/the new 'cleaned' table.\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#2b) What: Add logic for alerts (SendGrid); fire alert when issue found, correction made.\n",
    "#Who: Jesse\n",
    "\n",
    "#3) What: Verify that results look good in *_cleaned table(s).\n",
    "#Who: Bryan/Jesse/William(?)/anyone else who wants to help test\n",
    "\n",
    "#4) What: Set up cron job to run, initially, every 4-6 hours. Review results and make sure that:\n",
    "#Data is not thrown out, unnecessarily altered/integrity is retained\n",
    "#Any data corrections are done properly\n",
    "#Review / tweak anything else (see Bryan's notes in Asana: \"Data Cleaning Notes\" under \"Data Science Brainstorming\")\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#5) What: After 5-7 days of testing, 'deploy.' Cron job does not need to run as often; decide on interval. \n",
    "#Who: Jesse\n",
    "\n",
    "#6) What: Point all relevant queries to *_cleaned table(s)\n",
    "#Who: Bryan/Jesse/Emily\n",
    "\n",
    "\n",
    "#Will it tell the difference between an account that is consistently down or inconstently down.\n",
    "#After missing a reading, does a sensor ever get back to 100% (visualize this)\n",
    "#csv of sensor ids, date, and percentage (goes to a website?)\n",
    "#can it pull the peron's first and last names \n",
    "#first name last name (sensor id), dates, percentages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = psycopg2.connect(database ='heatseek', user = 'heatseekroot', password = 'wearecoolsoweseekheat')\n",
    "    cursor = connection.cursor() #Open a cursor to perform operations\n",
    "    \n",
    "    cursor.execute('SELECT * from users') #Executes the query\n",
    "    users = cursor.fetchall() #cursor.fetchone() for one line, fetchmany() for multiple lines, fetchall() for all lines\n",
    "    users = pd.DataFrame(users) #Saves 'users' as a pandas dataframe\n",
    "    users_header = [desc[0] for desc in cursor.description] #This gets the descriptions from cursor.description \n",
    "    #(names are in the 0th index)\n",
    "    users.columns = users_header #PD array's column names\n",
    "    \n",
    "    cursor.execute('SELECT * FROM readings;')\n",
    "    readings = cursor.fetchall()\n",
    "    readings = pd.DataFrame(readings)\n",
    "    readings_header = [desc[0] for desc in cursor.description]\n",
    "    readings.columns = readings_header\n",
    "    \n",
    "    cursor.execute('SELECT * FROM sensors;')\n",
    "    sensors = cursor.fetchall()\n",
    "    sensors = pd.DataFrame(sensors)\n",
    "    sensors_header = [desc[0] for desc in cursor.description]\n",
    "    sensors.columns = sensors_header\n",
    "    \n",
    "    cursor.close() \n",
    "    connection.close()\n",
    "    \n",
    "except psycopg2.DatabaseError, error:\n",
    "    print 'Error %s' % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensors_with_users_raw = np.intersect1d(users.id.unique(), sensors.user_id.unique()) #Returns the common ids in both the datasets.\n",
    "#sensors.loc[sensors.user_id, sensors_with_users]\n",
    "sensors_with_users = []\n",
    "for ids in sensors_with_users_raw:\n",
    "    sensors_with_users.append(int(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function will return if a sensor is polling faster than once per hour (i.e., test cases)\n",
    "    #It doesn't exist yet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THIS HAS TO BE RUN ON CLEAN DATA THAT HAS REMOVED CASES WHERE SENSORS ARE POLLING FASTER THAN ONCE PER HOUR.\n",
    "#This function takes (start date, end date, sensor id), returns % of failure\n",
    "def sensor_down(data, start_date, end_date, sensor_id): \n",
    "    \n",
    "    #This pulls up the tennant's first and last name.\n",
    "    try:\n",
    "        tennant_id = sensors.loc[sensors.id == sensor_id].user_id.values[0]\n",
    "        tennant_first_name = users.loc[users.id == tennant_id].first_name.values[0]\n",
    "        tennant_last_name = users.loc[users.id == tennant_id].last_name.values[0]\n",
    "    #Are these really not assigned?\n",
    "    except ValueError:\n",
    "        tennant_first_name = 'Not'\n",
    "        tennant_last_name = 'Assigned'\n",
    "    except IndexError:\n",
    "        tennant_first_name = 'Not'\n",
    "        tennant_last_name = 'Assigned'\n",
    "        \n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    sensor_readings = data.loc[data.sensor_id == sensor_id]\n",
    "    \n",
    "    #Converting to timestamps\n",
    "    for i in sensor_readings.index.values: #Iterates through all the index values\n",
    "        sensor_readings.loc[i, 'created_at'] = pd.Timestamp(sensor_readings.created_at[i])\n",
    "\n",
    "    #Using a boolean mask to select readings between the two dates \n",
    "    #(http://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates)   \n",
    "    mask = (sensor_readings['created_at'] > start_date) & (sensor_readings['created_at'] <= end_date)\n",
    "    masked_sensor_readings = sensor_readings.loc[mask] #Get all readings between the two dates\n",
    "    masked_sensor_readings = masked_sensor_readings.sort_values('created_at')\n",
    "    #We then calculate how many hours have passed for that specific sensor and date range\n",
    "    try:\n",
    "        sensor_readings_start_date = masked_sensor_readings.loc[masked_sensor_readings.index.values[0], 'created_at']\n",
    "        sensor_readings_end_date = \\\n",
    "        masked_sensor_readings.loc[masked_sensor_readings.index.values[len(masked_sensor_readings)-1], 'created_at']\n",
    "        timedelta_in_seconds =  sensor_readings_end_date - sensor_readings_start_date #This returns Timedelta object\n",
    "        timedelta_in_seconds = timedelta_in_seconds.total_seconds()\n",
    "        total_number_of_hours = timedelta_in_seconds/3600 + 1 #The +1 fixes the rounding error for now but IDK why yet.\n",
    "    except IndexError:\n",
    "        return [tennant_first_name, tennant_last_name, sensor_id, \"No valid readings.\"]\n",
    "    \n",
    "    proportion_of_uptime =len(masked_sensor_readings)/total_number_of_hours\n",
    "    \n",
    "    return [tennant_first_name, tennant_last_name, sensor_id, proportion_of_uptime*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print sensor_down(readings, '2015-01-01', '2015-06-01', 19)\n",
    "#users.loc[users['id'] == 19].first_name\n",
    "#readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function creates a simulated dataset of readings.\n",
    "def simulate_data(start_date, end_date, polling_rate, sensor_id): #polling_rate in minutes\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    #how many hours between the two dates:\n",
    "    timedelta_in_seconds = end_date-start_date\n",
    "    total_number_of_hours = timedelta_in_seconds.total_seconds()/(polling_rate*60)\n",
    "    \n",
    "    #Create an empty pandas dataframe\n",
    "    index = xrange(1,int(total_number_of_hours)+1)\n",
    "    columns = ['created_at', 'sensor_id']\n",
    "    simulated_readings = pd.DataFrame(index = index, columns = columns)\n",
    "    simulated_readings.loc[:,'sensor_id'] = sensor_id\n",
    "    \n",
    "    #Populate it with columns of 'create_at' dates\n",
    "    time_counter = start_date\n",
    "    for i in simulated_readings.index.values:\n",
    "        simulated_readings.loc[i,'created_at'] = time_counter\n",
    "        time_counter = time_counter + pd.Timedelta('00:%s:00' % polling_rate)\n",
    "\n",
    "    return simulated_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4    Harold\n",
      "Name: first_name, dtype: object, 4    Cooper\n",
      "Name: last_name, dtype: object, 8, 'No valid readings.']\n",
      "[58    Bill\n",
      "Name: first_name, dtype: object, 58    De Blasio\n",
      "Name: last_name, dtype: object, 9, 'No valid readings.']\n",
      "[55    Live Update\n",
      "Name: first_name, dtype: object, 55    Account0\n",
      "Name: last_name, dtype: object, 10, 'No valid readings.']\n",
      "[54    Live Update\n",
      "Name: first_name, dtype: object, 54    Account1\n",
      "Name: last_name, dtype: object, 12, 'No valid readings.']\n",
      "[56    Live Update\n",
      "Name: first_name, dtype: object, 56    Account2\n",
      "Name: last_name, dtype: object, 13, 'No valid readings.']\n",
      "[51    Live Update\n",
      "Name: first_name, dtype: object, 51    Account4\n",
      "Name: last_name, dtype: object, 15, 'No valid readings.']\n",
      "[12    Rebecca\n",
      "Name: first_name, dtype: object, 12    Sharp\n",
      "Name: last_name, dtype: object, 166, 'No valid readings.']\n",
      "[59    Carmen\n",
      "Name: first_name, dtype: object, 59    Vega-Rivera\n",
      "Name: last_name, dtype: object, 176, 'No valid readings.']\n",
      "[74    Anonymous\n",
      "Name: first_name, dtype: object, 74    Tenant\n",
      "Name: last_name, dtype: object, 39, 139.4709963723453]\n",
      "[67    Anonymous\n",
      "Name: first_name, dtype: object, 67    Tenant\n",
      "Name: last_name, dtype: object, 38, 294.93691627068654]\n",
      "[61    Anonymous\n",
      "Name: first_name, dtype: object, 61    Tenant\n",
      "Name: last_name, dtype: object, 22, 81.3953488372093]\n",
      "[82    Anonymous\n",
      "Name: first_name, dtype: object, 82    Tenant\n",
      "Name: last_name, dtype: object, 24, 19.51206292640294]\n",
      "[81    Nicole\n",
      "Name: first_name, dtype: object, 81    Carty\n",
      "Name: last_name, dtype: object, 25, 12.760388974850315]\n",
      "[79    Malaika\n",
      "Name: first_name, dtype: object, 79    Quashie\n",
      "Name: last_name, dtype: object, 26, 25.531847828085557]\n",
      "[77    Juan\n",
      "Name: first_name, dtype: object, 77    Mendoza\n",
      "Name: last_name, dtype: object, 36, 'No valid readings.']\n",
      "[72    Nicolas\n",
      "Name: first_name, dtype: object, 72    Orosco\n",
      "Name: last_name, dtype: object, 29, 35.25795723183984]\n",
      "[85    Palemon\n",
      "Name: first_name, dtype: object, 85    Galvez\n",
      "Name: last_name, dtype: object, 31, 32.12011274983168]\n",
      "[92    Jose\n",
      "Name: first_name, dtype: object, 92    Vicente Tacuri\n",
      "Name: last_name, dtype: object, 32, 32.460334731948]\n",
      "[91    Pedro\n",
      "Name: first_name, dtype: object, 91    Marin\n",
      "Name: last_name, dtype: object, 33, 33.60059843401591]\n",
      "[90    Florencia\n",
      "Name: first_name, dtype: object, 90    Tapia\n",
      "Name: last_name, dtype: object, 34, 31.28638352581541]\n",
      "[89    Manuel\n",
      "Name: first_name, dtype: object, 89    Yuicela\n",
      "Name: last_name, dtype: object, 35, 34.41283606920803]\n",
      "[19    Civic Hall\n",
      "Name: first_name, dtype: object, 19    Test Account 1\n",
      "Name: last_name, dtype: object, 42, 'No valid readings.']\n",
      "[5    Civic Hall\n",
      "Name: first_name, dtype: object, 5    Test Account 2\n",
      "Name: last_name, dtype: object, 43, 'No valid readings.']\n",
      "[20    Nicole\n",
      "Name: first_name, dtype: object, 20    Evangelista\n",
      "Name: last_name, dtype: object, 44, 'No valid readings.']\n",
      "[14    Adrianne\n",
      "Name: first_name, dtype: object, 14    Living Room\n",
      "Name: last_name, dtype: object, 152, 'No valid readings.']\n",
      "[6    Adrianne\n",
      "Name: first_name, dtype: object, 6    Jeffries Room\n",
      "Name: last_name, dtype: object, 144, 'No valid readings.']\n",
      "[23    Adrianne\n",
      "Name: first_name, dtype: object, 23    Jeffries Colgate's Room\n",
      "Name: last_name, dtype: object, 130, 'No valid readings.']\n",
      "[25    Victoria\n",
      "Name: first_name, dtype: object, 25    Watts\n",
      "Name: last_name, dtype: object, 123, 'No valid readings.']\n",
      "[70    Zui\n",
      "Name: first_name, dtype: object, 70    Mo\n",
      "Name: last_name, dtype: object, 139, 'No valid readings.']\n",
      "[87    Blue Ridge\n",
      "Name: first_name, dtype: object, 87    Labs\n",
      "Name: last_name, dtype: object, 179, 'No valid readings.']\n",
      "[95    Susana\n",
      "Name: first_name, dtype: object, 95    Robalino\n",
      "Name: last_name, dtype: object, 193, 'No valid readings.']\n",
      "[104    Noel\n",
      "Name: first_name, dtype: object, 104    Hidalgo\n",
      "Name: last_name, dtype: object, 102, 'No valid readings.']\n",
      "[98    Louis\n",
      "Name: first_name, dtype: object, 98    Bradford\n",
      "Name: last_name, dtype: object, 93, 'No valid readings.']\n",
      "[101    Christophe\n",
      "Name: first_name, dtype: object, 101    Veyssier\n",
      "Name: last_name, dtype: object, 168, 'No valid readings.']\n",
      "[103    Denton\n",
      "Name: first_name, dtype: object, 103    Sterling\n",
      "Name: last_name, dtype: object, 121, 'No valid readings.']\n",
      "[106    Armando\n",
      "Name: first_name, dtype: object, 106    Suarez-Cobian\n",
      "Name: last_name, dtype: object, 58, 'No valid readings.']\n",
      "[94    Tyler\n",
      "Name: first_name, dtype: object, 94    Wenzel\n",
      "Name: last_name, dtype: object, 132, 'No valid readings.']\n",
      "[113    David\n",
      "Name: first_name, dtype: object, 113    McCreery\n",
      "Name: last_name, dtype: object, 169, 'No valid readings.']\n",
      "[109    Ivo\n",
      "Name: first_name, dtype: object, 109    Rodrigues\n",
      "Name: last_name, dtype: object, 171, 'No valid readings.']\n",
      "[110    Michael\n",
      "Name: first_name, dtype: object, 110    Kasino\n",
      "Name: last_name, dtype: object, 107, 'No valid readings.']\n",
      "[114    Dale\n",
      "Name: first_name, dtype: object, 114    Goodson\n",
      "Name: last_name, dtype: object, 89, 'No valid readings.']\n",
      "[115    Elizabeth\n",
      "Name: first_name, dtype: object, 115    Ziff\n",
      "Name: last_name, dtype: object, 174, 'No valid readings.']\n",
      "[119    Eric\n",
      "Name: first_name, dtype: object, 119    Schles\n",
      "Name: last_name, dtype: object, 156, 'No valid readings.']\n",
      "[147    Lisa\n",
      "Name: first_name, dtype: object, 147    Mathis\n",
      "Name: last_name, dtype: object, 228, 'No valid readings.']\n",
      "[152    Kenny\n",
      "Name: first_name, dtype: object, 152    Harewood\n",
      "Name: last_name, dtype: object, 155, 'No valid readings.']\n",
      "[155    Valerie\n",
      "Name: first_name, dtype: object, 155    McPherson\n",
      "Name: last_name, dtype: object, 133, 'No valid readings.']\n",
      "[184    Jane\n",
      "Name: first_name, dtype: object, 184    Angel\n",
      "Name: last_name, dtype: object, 145, 'No valid readings.']\n",
      "[195    Dara\n",
      "Name: first_name, dtype: object, 195    Soukamneuth\n",
      "Name: last_name, dtype: object, 167, 'No valid readings.']\n",
      "[187    Helen\n",
      "Name: first_name, dtype: object, 187    Pugmire\n",
      "Name: last_name, dtype: object, 178, 'No valid readings.']\n",
      "[183    Redoneva\n",
      "Name: first_name, dtype: object, 183    Andrews\n",
      "Name: last_name, dtype: object, 181, 'No valid readings.']\n",
      "[185    Annery\n",
      "Name: first_name, dtype: object, 185    Ortiz\n",
      "Name: last_name, dtype: object, 214, 'No valid readings.']\n",
      "[182    Adrianne\n",
      "Name: first_name, dtype: object, 182    Santiago\n",
      "Name: last_name, dtype: object, 158, 'No valid readings.']\n",
      "[188    Wanda\n",
      "Name: first_name, dtype: object, 188    Young\n",
      "Name: last_name, dtype: object, 153, 'No valid readings.']\n",
      "[190    Miguel\n",
      "Name: first_name, dtype: object, 190    Rios\n",
      "Name: last_name, dtype: object, 159, 'No valid readings.']\n",
      "[116    Nancy\n",
      "Name: first_name, dtype: object, 116    De Jesús\n",
      "Name: last_name, dtype: object, 88, 'No valid readings.']\n",
      "[118    Virgen\n",
      "Name: first_name, dtype: object, 118    Martinez-Lopez\n",
      "Name: last_name, dtype: object, 90, 'No valid readings.']\n",
      "[145    Tanya\n",
      "Name: first_name, dtype: object, 145    Thomas\n",
      "Name: last_name, dtype: object, 273, 'No valid readings.']\n",
      "[125    Sunshine\n",
      "Name: first_name, dtype: object, 125    Jerido\n",
      "Name: last_name, dtype: object, 275, 'No valid readings.']\n",
      "[127    Flay \n",
      "Name: first_name, dtype: object, 127    Harper \n",
      "Name: last_name, dtype: object, 187, 'No valid readings.']\n",
      "[120    Maria\n",
      "Name: first_name, dtype: object, 120    Escobar\n",
      "Name: last_name, dtype: object, 161, 'No valid readings.']\n",
      "[121    Erin\n",
      "Name: first_name, dtype: object, 121    Whittendale \n",
      "Name: last_name, dtype: object, 180, 'No valid readings.']\n",
      "[124    Enerstin \n",
      "Name: first_name, dtype: object, 124    Williams\n",
      "Name: last_name, dtype: object, 128, 'No valid readings.']\n",
      "[123    Odalis\n",
      "Name: first_name, dtype: object, 123    Polanco\n",
      "Name: last_name, dtype: object, 201, 'No valid readings.']\n",
      "[128    Constance\n",
      "Name: first_name, dtype: object, 128    Taylor\n",
      "Name: last_name, dtype: object, 191, 'No valid readings.']\n",
      "[122    David\n",
      "Name: first_name, dtype: object, 122    Olshefski\n",
      "Name: last_name, dtype: object, 136, 'No valid readings.']\n",
      "[132    Indira\n",
      "Name: first_name, dtype: object, 132    Rodney\n",
      "Name: last_name, dtype: object, 194, 'No valid readings.']\n",
      "[142    Janelle\n",
      "Name: first_name, dtype: object, 142    Gedeon\n",
      "Name: last_name, dtype: object, 195, 'No valid readings.']\n",
      "[130    Lilia\n",
      "Name: first_name, dtype: object, 130    Lawson\n",
      "Name: last_name, dtype: object, 269, 'No valid readings.']\n",
      "[139    Charles\n",
      "Name: first_name, dtype: object, 139    Cordrey\n",
      "Name: last_name, dtype: object, 27, 'No valid readings.']\n",
      "[141    Roylyn \n",
      "Name: first_name, dtype: object, 141    Henery\n",
      "Name: last_name, dtype: object, 292, 'No valid readings.']\n",
      "[148    Desiree\n",
      "Name: first_name, dtype: object, 148    Browne\n",
      "Name: last_name, dtype: object, 11, 'No valid readings.']\n",
      "[149    Aurelia\n",
      "Name: first_name, dtype: object, 149    Cruz\n",
      "Name: last_name, dtype: object, 276, 'No valid readings.']\n",
      "[153    Iris\n",
      "Name: first_name, dtype: object, 153    Brown \n",
      "Name: last_name, dtype: object, 283, 'No valid readings.']\n",
      "[150    Arlene\n",
      "Name: first_name, dtype: object, 150    Riley\n",
      "Name: last_name, dtype: object, 160, 'No valid readings.']\n",
      "[151    Janice\n",
      "Name: first_name, dtype: object, 151    Lee\n",
      "Name: last_name, dtype: object, 284, 'No valid readings.']\n",
      "[171    Beatrice\n",
      "Name: first_name, dtype: object, 171    Rodriguez\n",
      "Name: last_name, dtype: object, 67, 'No valid readings.']\n",
      "[159    Loraine\n",
      "Name: first_name, dtype: object, 159    Dellamore\n",
      "Name: last_name, dtype: object, 19, 21.55698019653193]\n",
      "[163    Rita\n",
      "Name: first_name, dtype: object, 163    Kettrles\n",
      "Name: last_name, dtype: object, 190, 'No valid readings.']\n",
      "[157    Carolyn\n",
      "Name: first_name, dtype: object, 157    Butler \n",
      "Name: last_name, dtype: object, 271, 'No valid readings.']\n",
      "[158    Annette \n",
      "Name: first_name, dtype: object, 158    Cummings \n",
      "Name: last_name, dtype: object, 154, 'No valid readings.']\n",
      "[172    Tammy\n",
      "Name: first_name, dtype: object, 172    Brake\n",
      "Name: last_name, dtype: object, 184, 'No valid readings.']\n",
      "[162    Denise\n",
      "Name: first_name, dtype: object, 162    Johnson \n",
      "Name: last_name, dtype: object, 274, 'No valid readings.']\n",
      "[170    Ramona\n",
      "Name: first_name, dtype: object, 170    Garcia \n",
      "Name: last_name, dtype: object, 285, 'No valid readings.']\n",
      "[161    Wanda\n",
      "Name: first_name, dtype: object, 161    Perez\n",
      "Name: last_name, dtype: object, 268, 'No valid readings.']\n",
      "[168    Julio\n",
      "Name: first_name, dtype: object, 168    Belmonte \n",
      "Name: last_name, dtype: object, 282, 'No valid readings.']\n",
      "[173    Hazel-Ann\n",
      "Name: first_name, dtype: object, 173    FTC\n",
      "Name: last_name, dtype: object, 267, 'No valid readings.']\n",
      "[181    Christopher\n",
      "Name: first_name, dtype: object, 181    Lamar\n",
      "Name: last_name, dtype: object, 98, 'No valid readings.']\n",
      "[178    Korima\n",
      "Name: first_name, dtype: object, 178    Rock\n",
      "Name: last_name, dtype: object, 85, 'No valid readings.']\n",
      "[193    Nioka\n",
      "Name: first_name, dtype: object, 193    Jenkins\n",
      "Name: last_name, dtype: object, 288, 'No valid readings.']\n",
      "[196    Yolanda\n",
      "Name: first_name, dtype: object, 196    Rosado\n",
      "Name: last_name, dtype: object, 277, 'No valid readings.']\n"
     ]
    }
   ],
   "source": [
    "#Testing stuff\n",
    "#simulated_data = simulate_data('2015-01-01', '2015-01-31', 60, 30)\n",
    "#print sensor_down(readings, '2015-01-01', '2016-01-01', 26) #I think this works\n",
    "#print sensor_down(simulated_data, '2015-01-01', '2015-01-31', 30) #There's some rounding error\n",
    "\n",
    "for user_id in sensors_with_users:\n",
    "    #latest_id = sensors.loc[sensors.user_id==ids].id\n",
    "    #latest_id = latest_id.index.values[len(latest_id)-1]\n",
    "    #print sensors.loc[sensors.user_id == ids].id\n",
    "    #try:\n",
    "    print sensor_down(readings, '2015-01-01', '2016-01-01', sensors.loc[sensors.user_id == user_id].id.values[0])\n",
    "    #print users.loc[users.id == user_id].first_name\n",
    "    #except IndexError:\n",
    "    #print \"Error.\"\n",
    "    #print sensors.loc[sensors.user_id == user_id].id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function generates a report; we might want to make this a cron job.\n",
    "def generate_report(start_date, end_date):\n",
    "    report = []\n",
    "    sensor_ids = readings.sensor_id.unique()\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "    for ids in sensor_ids:\n",
    "        report.append(sensor_down(readings, start_date, end_date, ids))\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569.7073620084743"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "\n",
    "report = generate_report('2015-01-01','2016-01-01')\n",
    "header =['FirstName', 'LastName', 'SensorID', 'PercentageUptime']\n",
    "\n",
    "toc = time.clock()\n",
    "toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvoutput = open('report.csv', 'wb')\n",
    "writer = csv.writer(csvoutput)\n",
    "writer.writerow(header)\n",
    "for i in report:\n",
    "    writer.writerow(i)\n",
    "csvoutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What criteria do we want to use.\n",
    "\n",
    "#SENSOR NUMBERS AS IDENTIFIERS, SOME DEGREE OF SEVERITY OF PROBLEM (CATEGORICAL)\n",
    "\n",
    "#for the criteria we go, how do we define \"bad\"\n",
    "#total days\n",
    "#proportion of days (or clusters?)\n",
    "#temperature discrepancy\n",
    "#multiple apartments in the same building (how many % of the apartments in a building and how bad)\n",
    "#multiple buildings by the same landlord (how many % of the buildings a landlord owns are bad)\n",
    "#are our sensors failing in a specific building?\n",
    "\n",
    "#Getting rid of test cases:\n",
    "#1. Can we just delete by test IDs?\n",
    "#2. If testing was separated by a minute, we can find all test cases by looping through all users,\n",
    "#  and if they have a bunch of data that was collected within minutes, delete the user?\n",
    "\n",
    "#We first convert the string dates into datetime format\n",
    "sensordata['formatteddate'] = sensordata.created_at.apply(lambda x: pd.to_datetime(x,  format = \"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "#Then, one way of telling if a user_id was an actual user or a test case was to calculate the average timedelta for each user_id.\n",
    "#Timedeltas of 1min are tests, 1 hour are users (don't know if this is always true, but if no user has an average polling rate\n",
    "#of 1 min, we can use a bunch of methods to filter away test cases step by step).\n",
    "\n",
    "sensordata['averagetimedelta'] = 0.00 #makes a new column\n",
    "\n",
    "for i in sensordata.user_id.unique(): #for each user\n",
    "    timelist = sensordata.loc[sensordata.user_id == i, 'formatteddate'] #this gives us a list of all their times in timestamp\n",
    "    timedeltas = [] \n",
    "    for j in range(1, len(timelist)-1):\n",
    "        timedeltas.append(timelist.iloc[j] - timelist.iloc[j-1]) #list of differences in time between time point j and j-1\n",
    "    try:\n",
    "        #we print the user_id, followd by their average time delta from point j to j-1\n",
    "        print i, abs(sum(timedeltas, datetime.timedelta(0)))/len(timedeltas) #the average timedelta\n",
    "    except ZeroDivisionError: #some cases have too few points (and results in a zero division error)\n",
    "        #instead of breaking with we encounter a zerodivisionerror, just print the following:\n",
    "        print i, \"Too few data points?\"\n",
    "    sensordata.loc[sensordata.user_id == i, 'averagetimedelta'] = averagetimedeltas.total_seconds()\n",
    "\n",
    "#3. If user ids are recycled, we'll have to do a combination of those things.\n",
    "\n",
    "#Some sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Triage\n",
    "#We want to have a measure of which users are facing the most chronic problems.\n",
    "\n",
    "#Metric combining temperature difference and chronicity of problems\n",
    "\n",
    "#Write some code that subsets all the violation == 't' cases\n",
    "sensordataviolations = sensordata[sensordata.violation == 't'] #here it is.\n",
    "\n",
    "#Hackiest method: just number of violations/numberof nonviolations and sort users by that\n",
    "#That is, which users have had the most violations given the total number of readings \n",
    "\n",
    "violationsovertime = []\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    nonviolations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['f'] #Number of violations = 'f'\n",
    "    try:\n",
    "        violations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['t'] #Number of violations = 't'\n",
    "    except KeyError:\n",
    "        violations = 0    \n",
    "    sensordata.loc[sensordata.user_id == i, 'vfreq'] = float(violations)/float(nonviolations)\n",
    "    violationsovertime.append([i, (float(violations)/float(nonviolations))])\n",
    "\n",
    "#violations over time gives first the user_id, then the proportion of how many of their readings are violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stuff to do for fun\n",
    "\n",
    "#Variability/consistency\n",
    "#Which buildings have the least/most variable temperatures?\n",
    "#For this, we just calculate within-person variability (how much do sensor temperatures by the same user) vary as a function of time\n",
    "#We an use this same process to calculate variability between locations (e.g., just calculate variance for each location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, we loop over all unique users in the dataset and generate a measure of how long they've had the sensor running\n",
    "sensordata['totaltime'] = 0\n",
    "sensordata['vfreq'] = 0\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    firstentry = len(sensordata.loc[sensordata.user_id==i,'formatteddate']) #This gives us the index of the first timepoint\n",
    "    lasttime = sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[0] #This was the timestamp of the latest timepoint\n",
    "    firsttime =  sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[firstentry-1] #This was the timestamp of the first timepoint\n",
    "    sensordata.loc[sensordata.user_id == i, 'totaltime'] = lasttime - firsttime #This is the timedelta (over how long a period readings were made)\n",
    "    #print i, lasttime-firsttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>address</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>encrypted_password</th>\n",
       "      <th>reset_password_token</th>\n",
       "      <th>reset_password_sent_at</th>\n",
       "      <th>remember_created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>current_sign_in_at</th>\n",
       "      <th>last_sign_in_at</th>\n",
       "      <th>current_sign_in_ip</th>\n",
       "      <th>last_sign_in_ip</th>\n",
       "      <th>email</th>\n",
       "      <th>permissions</th>\n",
       "      <th>search_first_name</th>\n",
       "      <th>search_last_name</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sensor_codes_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>146</td>\n",
       "      <td>2015-02-24 00:30:30.376431</td>\n",
       "      <td>2015-02-24 14:25:41.991301</td>\n",
       "      <td>545 W 146th St Apt 64</td>\n",
       "      <td>Florencia</td>\n",
       "      <td>Tapia</td>\n",
       "      <td>$2a$10$G7FfZHPuzmwNp09PGZEDNeVxTHV0ocGcU07xajY...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>545w146thstapt64@heatseeknyc.com</td>\n",
       "      <td>100</td>\n",
       "      <td>florencia</td>\n",
       "      <td>tapia</td>\n",
       "      <td>10031</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                 created_at                 updated_at  \\\n",
       "90  146 2015-02-24 00:30:30.376431 2015-02-24 14:25:41.991301   \n",
       "\n",
       "                  address first_name last_name  \\\n",
       "90  545 W 146th St Apt 64  Florencia     Tapia   \n",
       "\n",
       "                                   encrypted_password reset_password_token  \\\n",
       "90  $2a$10$G7FfZHPuzmwNp09PGZEDNeVxTHV0ocGcU07xajY...                 None   \n",
       "\n",
       "   reset_password_sent_at remember_created_at         ...          \\\n",
       "90                   None                 NaT         ...           \n",
       "\n",
       "    current_sign_in_at last_sign_in_at current_sign_in_ip last_sign_in_ip  \\\n",
       "90                 NaT             NaT               None            None   \n",
       "\n",
       "                               email permissions  search_first_name  \\\n",
       "90  545w146thstapt64@heatseeknyc.com         100          florencia   \n",
       "\n",
       "   search_last_name zip_code sensor_codes_string  \n",
       "90            tapia    10031                None  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sensors.user_id.value_counts()\n",
    "#sensordata.violation.value_counts() #This returns the number of 't's and 'f's\n",
    "#np.sort(userdata.id.unique())\n",
    "#np.intersect1d(userdata.id.unique(), sensordata.user_id.unique()) #Returns the common ids in both the datasets.\n",
    "#readings.sensor_id.unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
