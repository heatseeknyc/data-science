{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0) What: Test steps 1,2,3 in local Postgres instance\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#1) What: Create a second table(s) within Postgres. I suggest just adding \"_cleaned\" to the name and use the same prefix. \n",
    "#The schema will remain the same. William - any objections here? We don't have a dev/staging Postgres instance, do we? \n",
    "#Who: Jesse\n",
    "\n",
    "#2a) What: Take Bryan's new Python and test each 'rule,' adding logic for writing to Postgres/the new 'cleaned' table.\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#2b) What: Add logic for alerts (SendGrid); fire alert when issue found, correction made.\n",
    "#Who: Jesse\n",
    "\n",
    "#3) What: Verify that results look good in *_cleaned table(s).\n",
    "#Who: Bryan/Jesse/William(?)/anyone else who wants to help test\n",
    "\n",
    "#4) What: Set up cron job to run, initially, every 4-6 hours. Review results and make sure that:\n",
    "#Data is not thrown out, unnecessarily altered/integrity is retained\n",
    "#Any data corrections are done properly\n",
    "#Review / tweak anything else (see Bryan's notes in Asana: \"Data Cleaning Notes\" under \"Data Science Brainstorming\")\n",
    "#Who: Bryan/Jesse\n",
    "\n",
    "#5) What: After 5-7 days of testing, 'deploy.' Cron job does not need to run as often; decide on interval. \n",
    "#Who: Jesse\n",
    "\n",
    "#6) What: Point all relevant queries to *_cleaned table(s)\n",
    "#Who: Bryan/Jesse/Emily\n",
    "\n",
    "\n",
    "#Will it tell the difference between an account that is consistently down or inconstently down.\n",
    "#After missing a reading, does a sensor ever get back to 100% (visualize this)\n",
    "#csv of sensor ids, date, and percentage (goes to a website?)\n",
    "#can it pull the peron's first and last names \n",
    "#first name last name (sensor id), dates, percentages below\n",
    "\n",
    "#Fix tennant names\n",
    "\n",
    "\n",
    "#Code to visualize stuff - for time periods for month and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import csv\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = psycopg2.connect(database ='heatseek', user = 'heatseekroot', password = 'wearecoolsoweseekheat')\n",
    "    cursor = connection.cursor() #Open a cursor to perform operations\n",
    "    \n",
    "    cursor.execute('SELECT * from users') #Executes the query\n",
    "    users = cursor.fetchall() #cursor.fetchone() for one line, fetchmany() for multiple lines, fetchall() for all lines\n",
    "    users = pd.DataFrame(users) #Saves 'users' as a pandas dataframe\n",
    "    users_header = [desc[0] for desc in cursor.description] #This gets the descriptions from cursor.description \n",
    "    #(names are in the 0th index)\n",
    "    users.columns = users_header #PD array's column names\n",
    "    \n",
    "    cursor.execute('SELECT * FROM readings;')\n",
    "    readings = cursor.fetchall()\n",
    "    readings = pd.DataFrame(readings)\n",
    "    readings_header = [desc[0] for desc in cursor.description]\n",
    "    readings.columns = readings_header\n",
    "    \n",
    "    cursor.execute('SELECT * FROM sensors;')\n",
    "    sensors = cursor.fetchall()\n",
    "    sensors = pd.DataFrame(sensors)\n",
    "    sensors_header = [desc[0] for desc in cursor.description]\n",
    "    sensors.columns = sensors_header\n",
    "    \n",
    "    cursor.close() \n",
    "    connection.close()\n",
    "    \n",
    "except psycopg2.DatabaseError, error:\n",
    "    print 'Error %s' % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This creates an array 'sensors_with_users' that consists of sensors that are currently assigned to users.\n",
    "sensors_with_users_raw = np.intersect1d(users.id.unique(), sensors.user_id.unique()) #Returns the common ids in both the datasets.\n",
    "#sensors.loc[sensors.user_id, sensors_with_users]\n",
    "sensors_with_users = []\n",
    "for ids in sensors_with_users_raw:\n",
    "    sensors_with_users.append(int(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function returns clean readings. #It doesn't exist yet\n",
    "#This function will return if a sensor is polling faster than once per hour (i.e., test cases)\n",
    "\n",
    "def dirty_data(dirty_readings, start_date = None, end_date = None):\n",
    "    if (start_date or end_date) == None:\n",
    "        start_date = pd.Timestamp('2000-01-01')\n",
    "        end_date = pd.Timestamp(datetime.datetime.now())\n",
    "    else:\n",
    "        start_date = pd.Timestamp(start_date)\n",
    "        end_date = pd.Timestamp(end_date)\n",
    "    \n",
    "    mask = (dirty_readings['created_at'] > start_date) & (dirty_readings['created_at'] <= end_date)\n",
    "    dirty_readings = dirty_readings.loc[mask]\n",
    "    \n",
    "    hot_ids = dirty_readings.loc[dirty_readings.temp > 90].sensor_id.unique() #Returns sensor IDs where indoor temp is > 90\n",
    "    cold_ids = dirty_readings.loc[dirty_readings.temp < 40].sensor_id.unique() #Returns sensor IDs where indoor temp is < 40\n",
    "    inside_colder_ids = dirty_readings.loc[dirty_readings.temp < dirty_readings.outdoor_temp].sensor_id.unique() #Returns sensor IDs where indoor temp is < outdoor temp\n",
    "    #Array of all the IDs above\n",
    "    all_ids = np.unique(np.concatenate((hot_ids, cold_ids, inside_colder_ids)))\n",
    "    all_ids = all_ids[~np.isnan(all_ids)]\n",
    "    #Create an empty dataframe with the IDs as indices\n",
    "    report = pd.DataFrame(index=all_ids,columns=['UserID','SensorID', 'Outside90', 'Inside40', 'InsideColderOutside'])\n",
    "    #Fill in the specific conditions as '1'\n",
    "    report.Outside90 = report.loc[hot_ids].Outside90.fillna(1)\n",
    "    report.Inside40 = report.loc[cold_ids].Inside40.fillna(1)\n",
    "    report.InsideColderOutside = report.loc[inside_colder_ids].InsideColderOutside.fillna(1)\n",
    "    report = report.fillna(0)\n",
    "    report.SensorID = report.index\n",
    "    \n",
    "    #Fill in UserIDs\n",
    "    problem_ids = sensors[sensors.id.isin(all_ids)]\n",
    "    for index in report.index.values:\n",
    "        index = int(index)\n",
    "        try:\n",
    "            report.loc[index, 'UserID'] = sensors.loc[index, 'user_id']\n",
    "        except KeyError:\n",
    "            report.loc[index, 'UserID']  = 'No such user in sensors table.'\n",
    "    return report\n",
    "        \n",
    "\n",
    "\n",
    "def clean_data(dirty_readings):\n",
    "    cleaner_readings = dirty_readings[dirty_readings.sensor_id.notnull()] #Remove cases where there are no sensor IDs\n",
    "    return cleaner_readings\n",
    "    \n",
    "clean_readings = clean_data(readings)\n",
    "report = dirty_data(readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function takes (start date, end date, sensor id), returns % of failure\n",
    "def sensor_down(data, start_date, end_date, sensor_id): \n",
    "    \n",
    "    #This pulls up the tennant's first and last name.\n",
    "    try:\n",
    "        tennant_id = int(sensors.loc[sensors.id == sensor_id].user_id.values[0])\n",
    "        tennant_first_name = users.loc[users.id == tennant_id].first_name.values[-1] #This pulls up the first name on the list (not the most recent)\n",
    "        tennant_last_name = users.loc[users.id == tennant_id].last_name.values[-1]\n",
    "    #Are these really not assigned?\n",
    "    except ValueError:\n",
    "        tennant_id = 'None'\n",
    "        tennant_first_name = 'Not'\n",
    "        tennant_last_name = 'Assigned'\n",
    "    except IndexError:\n",
    "        tennant_id = 'None'\n",
    "        tennant_first_name = 'Not'\n",
    "        tennant_last_name = 'Assigned'\n",
    "        \n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    sensor_readings = data.loc[data.sensor_id == sensor_id]\n",
    "    \n",
    "    #Converting to timestamps\n",
    "    #for i in sensor_readings.index.values: #Iterates through all the index values\n",
    "        #sensor_readings.loc[i, 'created_at'] = pd.Timestamp(sensor_readings.created_at[i])\n",
    "    #Using map instead of for loop (about 15-20x faster)\n",
    "    try:\n",
    "        sensor_readings.loc[:, 'created_at'] = map(pd.Timestamp, sensor_readings.created_at)\n",
    "    except TypeError:\n",
    "        tennant_first_name = 'Mapping Error'\n",
    "        tennant_last_name = 'Only One Entry'\n",
    "        pass\n",
    "    #Using list comprehensions (as efficient as map)\n",
    "    #sensor_readings.loc[:, 'created_at'] = [pd.Timestamp(x) for x in sensor_readings.created_at]\n",
    "        \n",
    "    #Using a boolean mask to select readings between the two dates \n",
    "    #(http://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates)   \n",
    "    mask = (sensor_readings['created_at'] > start_date) & (sensor_readings['created_at'] <= end_date)\n",
    "    masked_sensor_readings = sensor_readings.loc[mask] #Get all readings between the two dates\n",
    "    masked_sensor_readings = masked_sensor_readings.sort_values('created_at')\n",
    "    #We then calculate how many hours have passed for that specific sensor and date range\n",
    "    try:\n",
    "        sensor_readings_start_date = masked_sensor_readings.loc[masked_sensor_readings.index.values[0], 'created_at']\n",
    "        sensor_readings_end_date = \\\n",
    "        masked_sensor_readings.loc[masked_sensor_readings.index.values[len(masked_sensor_readings)-1], 'created_at']\n",
    "        timedelta_in_seconds =  sensor_readings_end_date - sensor_readings_start_date #This returns Timedelta object\n",
    "        timedelta_in_seconds = timedelta_in_seconds.total_seconds()\n",
    "        total_number_of_hours = timedelta_in_seconds/3600 + 1 #The +1 fixes the rounding error for now but IDK why yet.\n",
    "        \n",
    "        hours_in_date_range = ((end_date-start_date).total_seconds())/3600 + 1\n",
    "        \n",
    "    except IndexError:\n",
    "        return [tennant_first_name, tennant_last_name, sensor_id, tennant_id, \"No valid readings during this time frame.\"]\n",
    "    \n",
    "    proportion_of_total_uptime = (len(masked_sensor_readings)/hours_in_date_range) * 100 #Proportion of uptime over TOTAL HOURS\n",
    "    proportion_within_sensor_uptime = (len(masked_sensor_readings)/total_number_of_hours) * 100 #Proportion of uptime for the sensor's first and last uploaded dates.\n",
    "    if proportion_within_sensor_uptime <= 100.1:\n",
    "        return [tennant_first_name, tennant_last_name, sensor_id, tennant_id, proportion_of_total_uptime, proportion_within_sensor_uptime]\n",
    "    else:\n",
    "        return [tennant_first_name, tennant_last_name, sensor_id, tennant_id, proportion_of_total_uptime, proportion_within_sensor_uptime, 'Sensor has readings more frequent than once per hour. Check readings table.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Loraine', 'Dellamore', 19, 245, 99.31034482758618, 99.99980709913753]\n"
     ]
    }
   ],
   "source": [
    "print sensor_down(readings, '2016-02-01', '2016-02-07', 19)\n",
    "#mask = (readings['created_at'] > pd.Timestamp('2016-02-01')) & (readings['created_at'] <= pd.Timestamp('2016-02-07'))\n",
    "#readings.loc[readings.sensor_id == 296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function creates a simulated dataset of readings.\n",
    "def simulate_data(start_date, end_date, polling_rate, sensor_id): #polling_rate in minutes\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    #how many hours between the two dates:\n",
    "    timedelta_in_seconds = end_date-start_date\n",
    "    total_number_of_hours = timedelta_in_seconds.total_seconds()/(polling_rate*60)\n",
    "    \n",
    "    #Create an empty pandas dataframe\n",
    "    index = xrange(1,int(total_number_of_hours)+1)\n",
    "    columns = ['created_at', 'sensor_id']\n",
    "    simulated_readings = pd.DataFrame(index = index, columns = columns)\n",
    "    simulated_readings.loc[:,'sensor_id'] = sensor_id\n",
    "    \n",
    "    #Populate it with columns of 'create_at' dates\n",
    "    time_counter = start_date\n",
    "    for i in simulated_readings.index.values:\n",
    "        simulated_readings.loc[i,'created_at'] = time_counter\n",
    "        time_counter = time_counter + pd.Timedelta('00:%s:00' % polling_rate)\n",
    "   \n",
    "    return simulated_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing stuff\n",
    "#simulated_data = simulate_data('2015-01-01', '2015-01-31', 60, 30)\n",
    "#print sensor_down(readings, '2015-01-01', '2016-01-01', 26) #I think this works\n",
    "#print sensor_down(simulated_data, '2015-01-01', '2015-01-31', 30) #There's some rounding error\n",
    "#for user_id in sensors_with_users:\n",
    "    #latest_id = sensors.loc[sensors.user_id==ids].id\n",
    "    #latest_id = latest_id.index.values[len(latest_id)-1]\n",
    "    #print sensors.loc[sensors.user_id == ids].id\n",
    "    #try:\n",
    "    #print sensor_down(readings, '2015-01-01', '2016-01-01', sensors.loc[sensors.user_id == user_id].id.values[0])\n",
    "    #print users.loc[users.id == user_id].first_name\n",
    "    #except IndexError:\n",
    "    #print \"Error.\"\n",
    "    #print sensors.loc[sensors.user_id == user_id].id.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function generates a report; we might want to make this a cron job.\n",
    "def generate_report(start_date, end_date):\n",
    "    report = []\n",
    "    sensor_ids = readings.sensor_id.unique()\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "    for ids in sensor_ids:\n",
    "        report.append(sensor_down(readings, start_date, end_date, ids))\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.59626564107334"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "\n",
    "report = generate_report('2016-02-01','2016-02-07')\n",
    "header =['FirstName', 'LastName', 'SensorID', 'UserID', 'Percentage of uptime in daterange', 'Percentage of uptime while sensor was transmitting']\n",
    "\n",
    "toc = time.clock()\n",
    "toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvoutput = open('report.csv', 'wb')\n",
    "writer = csv.writer(csvoutput)\n",
    "writer.writerow(header)\n",
    "for i in report:\n",
    "    writer.writerow(i)\n",
    "csvoutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sensordata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-0bc7b148d9be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#We first convert the string dates into datetime format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msensordata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'formatteddate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msensordata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%Y-%m-%d %H:%M\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#Then, one way of telling if a user_id was an actual user or a test case was to calculate the average timedelta for each user_id.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sensordata' is not defined"
     ]
    }
   ],
   "source": [
    "#What criteria do we want to use.\n",
    "\n",
    "#SENSOR NUMBERS AS IDENTIFIERS, SOME DEGREE OF SEVERITY OF PROBLEM (CATEGORICAL)\n",
    "\n",
    "#for the criteria we go, how do we define \"bad\"\n",
    "#total days\n",
    "#proportion of days (or clusters?)\n",
    "#temperature discrepancy\n",
    "#multiple apartments in the same building (how many % of the apartments in a building and how bad)\n",
    "#multiple buildings by the same landlord (how many % of the buildings a landlord owns are bad)\n",
    "#are our sensors failing in a specific building?\n",
    "\n",
    "#Getting rid of test cases:\n",
    "#1. Can we just delete by test IDs?\n",
    "#2. If testing was separated by a minute, we can find all test cases by looping through all users,\n",
    "#  and if they have a bunch of data that was collected within minutes, delete the user?\n",
    "\n",
    "#We first convert the string dates into datetime format\n",
    "sensordata['formatteddate'] = sensordata.created_at.apply(lambda x: pd.to_datetime(x,  format = \"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "#Then, one way of telling if a user_id was an actual user or a test case was to calculate the average timedelta for each user_id.\n",
    "#Timedeltas of 1min are tests, 1 hour are users (don't know if this is always true, but if no user has an average polling rate\n",
    "#of 1 min, we can use a bunch of methods to filter away test cases step by step).\n",
    "\n",
    "sensordata['averagetimedelta'] = 0.00 #makes a new column\n",
    "\n",
    "for i in sensordata.user_id.unique(): #for each user\n",
    "    timelist = sensordata.loc[sensordata.user_id == i, 'formatteddate'] #this gives us a list of all their times in timestamp\n",
    "    timedeltas = [] \n",
    "    for j in range(1, len(timelist)-1):\n",
    "        timedeltas.append(timelist.iloc[j] - timelist.iloc[j-1]) #list of differences in time between time point j and j-1\n",
    "    try:\n",
    "        #we print the user_id, followd by their average time delta from point j to j-1\n",
    "        print i, abs(sum(timedeltas, datetime.timedelta(0)))/len(timedeltas) #the average timedelta\n",
    "    except ZeroDivisionError: #some cases have too few points (and results in a zero division error)\n",
    "        #instead of breaking with we encounter a zerodivisionerror, just print the following:\n",
    "        print i, \"Too few data points?\"\n",
    "    sensordata.loc[sensordata.user_id == i, 'averagetimedelta'] = averagetimedeltas.total_seconds()\n",
    "\n",
    "#3. If user ids are recycled, we'll have to do a combination of those things.\n",
    "\n",
    "#Some sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Triage\n",
    "#We want to have a measure of which users are facing the most chronic problems.\n",
    "\n",
    "#Metric combining temperature difference and chronicity of problems\n",
    "\n",
    "#Write some code that subsets all the violation == 't' cases\n",
    "sensordataviolations = sensordata[sensordata.violation == 't'] #here it is.\n",
    "\n",
    "#Hackiest method: just number of violations/numberof nonviolations and sort users by that\n",
    "#That is, which users have had the most violations given the total number of readings \n",
    "\n",
    "violationsovertime = []\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    nonviolations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['f'] #Number of violations = 'f'\n",
    "    try:\n",
    "        violations = sensordata.loc[sensordata.user_id == i, 'violation'].value_counts()['t'] #Number of violations = 't'\n",
    "    except KeyError:\n",
    "        violations = 0    \n",
    "    sensordata.loc[sensordata.user_id == i, 'vfreq'] = float(violations)/float(nonviolations)\n",
    "    violationsovertime.append([i, (float(violations)/float(nonviolations))])\n",
    "\n",
    "#violations over time gives first the user_id, then the proportion of how many of their readings are violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stuff to do for fun\n",
    "\n",
    "#Variability/consistency\n",
    "#Which buildings have the least/most variable temperatures?\n",
    "#For this, we just calculate within-person variability (how much do sensor temperatures by the same user) vary as a function of time\n",
    "#We an use this same process to calculate variability between locations (e.g., just calculate variance for each location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, we loop over all unique users in the dataset and generate a measure of how long they've had the sensor running\n",
    "sensordata['totaltime'] = 0\n",
    "sensordata['vfreq'] = 0\n",
    "\n",
    "for i in sensordata.user_id.unique():\n",
    "    firstentry = len(sensordata.loc[sensordata.user_id==i,'formatteddate']) #This gives us the index of the first timepoint\n",
    "    lasttime = sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[0] #This was the timestamp of the latest timepoint\n",
    "    firsttime =  sensordata.loc[sensordata.user_id == i, 'formatteddate'].iloc[firstentry-1] #This was the timestamp of the first timepoint\n",
    "    sensordata.loc[sensordata.user_id == i, 'totaltime'] = lasttime - firsttime #This is the timedelta (over how long a period readings were made)\n",
    "    #print i, lasttime-firsttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>temp</th>\n",
       "      <th>twine_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>outdoor_temp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133078</th>\n",
       "      <td>526522</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 06:09:09</td>\n",
       "      <td>2016-01-25 04:48:44.443183</td>\n",
       "      <td>135</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133075</th>\n",
       "      <td>526194</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 21:09:09</td>\n",
       "      <td>2016-01-25 04:48:44.400827</td>\n",
       "      <td>135</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133081</th>\n",
       "      <td>526507</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 22:09:09</td>\n",
       "      <td>2015-02-22 03:36:22.991260</td>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133080</th>\n",
       "      <td>526489</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 23:09:09</td>\n",
       "      <td>2015-02-22 03:36:12.455004</td>\n",
       "      <td>135</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133077</th>\n",
       "      <td>526516</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 00:09:09</td>\n",
       "      <td>2016-01-25 04:48:44.420321</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133076</th>\n",
       "      <td>526500</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 01:09:09</td>\n",
       "      <td>2016-01-25 04:48:44.410440</td>\n",
       "      <td>135</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133083</th>\n",
       "      <td>526561</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 04:09:09</td>\n",
       "      <td>2016-01-25 04:48:44.477740</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133086</th>\n",
       "      <td>526567</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 05:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.417950</td>\n",
       "      <td>135</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133097</th>\n",
       "      <td>526583</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 06:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.472798</td>\n",
       "      <td>135</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>526594</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 07:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.496304</td>\n",
       "      <td>135</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133101</th>\n",
       "      <td>526607</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 08:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.664260</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133102</th>\n",
       "      <td>526621</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 09:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.676312</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133104</th>\n",
       "      <td>526633</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 10:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.698500</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133108</th>\n",
       "      <td>526647</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.743618</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133110</th>\n",
       "      <td>526657</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.765060</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133148</th>\n",
       "      <td>526668</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.226855</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133151</th>\n",
       "      <td>526680</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 14:09:09</td>\n",
       "      <td>2016-01-25 04:49:01.276720</td>\n",
       "      <td>135</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133115</th>\n",
       "      <td>526694</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 15:09:09</td>\n",
       "      <td>2016-01-25 04:49:00.832766</td>\n",
       "      <td>135</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133120</th>\n",
       "      <td>526704</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 16:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.885975</td>\n",
       "      <td>135</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133123</th>\n",
       "      <td>526713</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 17:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.919456</td>\n",
       "      <td>135</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133127</th>\n",
       "      <td>526724</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:09:10</td>\n",
       "      <td>2016-01-25 04:49:00.969386</td>\n",
       "      <td>135</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133131</th>\n",
       "      <td>526737</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 19:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.057189</td>\n",
       "      <td>135</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133154</th>\n",
       "      <td>526744</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 20:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.312667</td>\n",
       "      <td>135</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133160</th>\n",
       "      <td>526760</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 21:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.382816</td>\n",
       "      <td>135</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133165</th>\n",
       "      <td>526772</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 22:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.443789</td>\n",
       "      <td>135</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133169</th>\n",
       "      <td>526783</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 23:09:10</td>\n",
       "      <td>2016-01-25 04:49:01.490072</td>\n",
       "      <td>135</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>526791</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 00:09:10</td>\n",
       "      <td>2016-01-25 04:54:29.637176</td>\n",
       "      <td>135</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>526801</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 01:09:10</td>\n",
       "      <td>2016-01-25 04:54:29.692262</td>\n",
       "      <td>135</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>526814</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 02:09:10</td>\n",
       "      <td>2016-01-25 04:54:46.302491</td>\n",
       "      <td>135</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>526820</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 03:09:10</td>\n",
       "      <td>2016-01-25 04:54:46.337705</td>\n",
       "      <td>135</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125419</th>\n",
       "      <td>594767</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 15:03:10</td>\n",
       "      <td>2016-02-13 18:18:12.300879</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125449</th>\n",
       "      <td>594797</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 16:03:10</td>\n",
       "      <td>2016-02-13 18:18:53.687502</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125574</th>\n",
       "      <td>594827</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 17:03:10</td>\n",
       "      <td>2016-02-13 18:19:35.305091</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125602</th>\n",
       "      <td>594855</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 18:03:10</td>\n",
       "      <td>2016-02-13 18:24:07.053451</td>\n",
       "      <td>135</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125923</th>\n",
       "      <td>594886</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 19:03:10</td>\n",
       "      <td>2016-02-13 19:08:57.442103</td>\n",
       "      <td>135</td>\n",
       "      <td>20</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125727</th>\n",
       "      <td>594916</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 20:03:10</td>\n",
       "      <td>2016-02-13 20:09:46.917118</td>\n",
       "      <td>135</td>\n",
       "      <td>18</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125756</th>\n",
       "      <td>594945</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 21:03:10</td>\n",
       "      <td>2016-02-13 21:10:34.835127</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125786</th>\n",
       "      <td>594975</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 22:03:10</td>\n",
       "      <td>2016-02-13 22:07:27.662220</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125939</th>\n",
       "      <td>595003</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-13 23:03:10</td>\n",
       "      <td>2016-02-13 23:08:14.294838</td>\n",
       "      <td>135</td>\n",
       "      <td>12</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126303</th>\n",
       "      <td>595200</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 00:03:10</td>\n",
       "      <td>2016-02-14 00:07:53.944439</td>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126332</th>\n",
       "      <td>595229</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 01:03:10</td>\n",
       "      <td>2016-02-14 01:08:41.442709</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126390</th>\n",
       "      <td>595259</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 02:03:10</td>\n",
       "      <td>2016-02-14 02:09:32.620839</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126443</th>\n",
       "      <td>595288</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 03:03:10</td>\n",
       "      <td>2016-02-15 16:33:29.935914</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126501</th>\n",
       "      <td>595317</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 04:03:10</td>\n",
       "      <td>2016-02-15 16:34:00.968598</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126544</th>\n",
       "      <td>595345</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 05:03:10</td>\n",
       "      <td>2016-02-15 16:34:31.048499</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126570</th>\n",
       "      <td>595371</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 06:03:10</td>\n",
       "      <td>2016-02-15 16:34:59.017811</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126599</th>\n",
       "      <td>595400</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 07:03:10</td>\n",
       "      <td>2016-02-15 16:35:30.130145</td>\n",
       "      <td>135</td>\n",
       "      <td>-1</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126733</th>\n",
       "      <td>595429</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 08:03:10</td>\n",
       "      <td>2016-02-15 16:36:01.445840</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126752</th>\n",
       "      <td>595458</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 09:03:10</td>\n",
       "      <td>2016-02-15 16:36:32.679226</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126782</th>\n",
       "      <td>595488</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 10:03:10</td>\n",
       "      <td>2016-02-15 16:37:04.903503</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126810</th>\n",
       "      <td>595516</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 11:03:10</td>\n",
       "      <td>2016-02-15 16:37:34.948515</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126934</th>\n",
       "      <td>595545</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 12:03:10</td>\n",
       "      <td>2016-02-15 16:38:06.229288</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126962</th>\n",
       "      <td>595573</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 13:03:10</td>\n",
       "      <td>2016-02-15 16:38:36.335556</td>\n",
       "      <td>135</td>\n",
       "      <td>12</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126990</th>\n",
       "      <td>595601</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 14:03:10</td>\n",
       "      <td>2016-02-15 16:39:06.386855</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127018</th>\n",
       "      <td>595629</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 15:03:10</td>\n",
       "      <td>2016-02-15 16:39:36.537967</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127141</th>\n",
       "      <td>595657</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 16:03:10</td>\n",
       "      <td>2016-02-15 16:40:06.836885</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127168</th>\n",
       "      <td>595684</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 17:03:10</td>\n",
       "      <td>2016-02-15 16:40:35.853490</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127290</th>\n",
       "      <td>595798</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 18:03:10</td>\n",
       "      <td>2016-02-15 20:19:31.758193</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127319</th>\n",
       "      <td>595827</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 19:03:10</td>\n",
       "      <td>2016-02-15 20:20:03.079842</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127347</th>\n",
       "      <td>595855</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-14 20:03:10</td>\n",
       "      <td>2016-02-15 20:20:33.218724</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  temp  twine_id          created_at                 updated_at  \\\n",
       "133078  526522    63       NaN 2015-02-19 06:09:09 2016-01-25 04:48:44.443183   \n",
       "133075  526194    63       NaN 2015-02-19 21:09:09 2016-01-25 04:48:44.400827   \n",
       "133081  526507    63       NaN 2015-02-19 22:09:09 2015-02-22 03:36:22.991260   \n",
       "133080  526489    63       NaN 2015-02-19 23:09:09 2015-02-22 03:36:12.455004   \n",
       "133077  526516    63       NaN 2015-02-20 00:09:09 2016-01-25 04:48:44.420321   \n",
       "133076  526500    65       NaN 2015-02-20 01:09:09 2016-01-25 04:48:44.410440   \n",
       "133083  526561    63       NaN 2015-02-22 04:09:09 2016-01-25 04:48:44.477740   \n",
       "133086  526567    63       NaN 2015-02-22 05:09:09 2016-01-25 04:49:00.417950   \n",
       "133097  526583    63       NaN 2015-02-22 06:09:10 2016-01-25 04:49:00.472798   \n",
       "133098  526594    62       NaN 2015-02-22 07:09:09 2016-01-25 04:49:00.496304   \n",
       "133101  526607    62       NaN 2015-02-22 08:09:10 2016-01-25 04:49:00.664260   \n",
       "133102  526621    62       NaN 2015-02-22 09:09:09 2016-01-25 04:49:00.676312   \n",
       "133104  526633    63       NaN 2015-02-22 10:09:09 2016-01-25 04:49:00.698500   \n",
       "133108  526647    63       NaN 2015-02-22 11:09:10 2016-01-25 04:49:00.743618   \n",
       "133110  526657    65       NaN 2015-02-22 12:09:09 2016-01-25 04:49:00.765060   \n",
       "133148  526668    65       NaN 2015-02-22 13:09:10 2016-01-25 04:49:01.226855   \n",
       "133151  526680    65       NaN 2015-02-22 14:09:09 2016-01-25 04:49:01.276720   \n",
       "133115  526694    65       NaN 2015-02-22 15:09:09 2016-01-25 04:49:00.832766   \n",
       "133120  526704    65       NaN 2015-02-22 16:09:10 2016-01-25 04:49:00.885975   \n",
       "133123  526713    65       NaN 2015-02-22 17:09:10 2016-01-25 04:49:00.919456   \n",
       "133127  526724    66       NaN 2015-02-22 18:09:10 2016-01-25 04:49:00.969386   \n",
       "133131  526737    66       NaN 2015-02-22 19:09:10 2016-01-25 04:49:01.057189   \n",
       "133154  526744    66       NaN 2015-02-22 20:09:10 2016-01-25 04:49:01.312667   \n",
       "133160  526760    65       NaN 2015-02-22 21:09:10 2016-01-25 04:49:01.382816   \n",
       "133165  526772    65       NaN 2015-02-22 22:09:10 2016-01-25 04:49:01.443789   \n",
       "133169  526783    66       NaN 2015-02-22 23:09:10 2016-01-25 04:49:01.490072   \n",
       "643     526791    66       NaN 2015-02-23 00:09:10 2016-01-25 04:54:29.637176   \n",
       "758     526801    66       NaN 2015-02-23 01:09:10 2016-01-25 04:54:29.692262   \n",
       "915     526814    65       NaN 2015-02-23 02:09:10 2016-01-25 04:54:46.302491   \n",
       "918     526820    66       NaN 2015-02-23 03:09:10 2016-01-25 04:54:46.337705   \n",
       "...        ...   ...       ...                 ...                        ...   \n",
       "125419  594767   112       NaN 2016-02-13 15:03:10 2016-02-13 18:18:12.300879   \n",
       "125449  594797   111       NaN 2016-02-13 16:03:10 2016-02-13 18:18:53.687502   \n",
       "125574  594827   110       NaN 2016-02-13 17:03:10 2016-02-13 18:19:35.305091   \n",
       "125602  594855   112       NaN 2016-02-13 18:03:10 2016-02-13 18:24:07.053451   \n",
       "125923  594886   111       NaN 2016-02-13 19:03:10 2016-02-13 19:08:57.442103   \n",
       "125727  594916   110       NaN 2016-02-13 20:03:10 2016-02-13 20:09:46.917118   \n",
       "125756  594945   112       NaN 2016-02-13 21:03:10 2016-02-13 21:10:34.835127   \n",
       "125786  594975   111       NaN 2016-02-13 22:03:10 2016-02-13 22:07:27.662220   \n",
       "125939  595003   112       NaN 2016-02-13 23:03:10 2016-02-13 23:08:14.294838   \n",
       "126303  595200   112       NaN 2016-02-14 00:03:10 2016-02-14 00:07:53.944439   \n",
       "126332  595229   112       NaN 2016-02-14 01:03:10 2016-02-14 01:08:41.442709   \n",
       "126390  595259   112       NaN 2016-02-14 02:03:10 2016-02-14 02:09:32.620839   \n",
       "126443  595288   113       NaN 2016-02-14 03:03:10 2016-02-15 16:33:29.935914   \n",
       "126501  595317   112       NaN 2016-02-14 04:03:10 2016-02-15 16:34:00.968598   \n",
       "126544  595345   111       NaN 2016-02-14 05:03:10 2016-02-15 16:34:31.048499   \n",
       "126570  595371   110       NaN 2016-02-14 06:03:10 2016-02-15 16:34:59.017811   \n",
       "126599  595400   112       NaN 2016-02-14 07:03:10 2016-02-15 16:35:30.130145   \n",
       "126733  595429   113       NaN 2016-02-14 08:03:10 2016-02-15 16:36:01.445840   \n",
       "126752  595458   112       NaN 2016-02-14 09:03:10 2016-02-15 16:36:32.679226   \n",
       "126782  595488   112       NaN 2016-02-14 10:03:10 2016-02-15 16:37:04.903503   \n",
       "126810  595516   112       NaN 2016-02-14 11:03:10 2016-02-15 16:37:34.948515   \n",
       "126934  595545   112       NaN 2016-02-14 12:03:10 2016-02-15 16:38:06.229288   \n",
       "126962  595573   113       NaN 2016-02-14 13:03:10 2016-02-15 16:38:36.335556   \n",
       "126990  595601   112       NaN 2016-02-14 14:03:10 2016-02-15 16:39:06.386855   \n",
       "127018  595629   112       NaN 2016-02-14 15:03:10 2016-02-15 16:39:36.537967   \n",
       "127141  595657   112       NaN 2016-02-14 16:03:10 2016-02-15 16:40:06.836885   \n",
       "127168  595684   112       NaN 2016-02-14 17:03:10 2016-02-15 16:40:35.853490   \n",
       "127290  595798   113       NaN 2016-02-14 18:03:10 2016-02-15 20:19:31.758193   \n",
       "127319  595827   112       NaN 2016-02-14 19:03:10 2016-02-15 20:20:03.079842   \n",
       "127347  595855   112       NaN 2016-02-14 20:03:10 2016-02-15 20:20:33.218724   \n",
       "\n",
       "        user_id  outdoor_temp  sensor_id violation  \n",
       "133078      135            22         26     False  \n",
       "133075      135            18         26      True  \n",
       "133081      135            10         26      True  \n",
       "133080      135             8         26      True  \n",
       "133077      135            14         26      True  \n",
       "133076      135            13         26      True  \n",
       "133083      135            32         26     False  \n",
       "133086      135            33         26     False  \n",
       "133097      135            33         26     False  \n",
       "133098      135            33         26     False  \n",
       "133101      135            32         26     False  \n",
       "133102      135            32         26     False  \n",
       "133104      135            32         26     False  \n",
       "133108      135            32         26      True  \n",
       "133110      135            32         26      True  \n",
       "133148      135            32         26      True  \n",
       "133151      135            33         26      True  \n",
       "133115      135            33         26      True  \n",
       "133120      135            36         26      True  \n",
       "133123      135            38         26      True  \n",
       "133127      135            41         26      True  \n",
       "133131      135            43         26      True  \n",
       "133154      135            43         26      True  \n",
       "133160      135            41         26      True  \n",
       "133165      135            40         26      True  \n",
       "133169      135            40         26      True  \n",
       "643         135            40         26      True  \n",
       "758         135            40         26      True  \n",
       "915         135            39         26      True  \n",
       "918         135            39         26     False  \n",
       "...         ...           ...        ...       ...  \n",
       "125419      135           NaN        188     False  \n",
       "125449      135           NaN        188     False  \n",
       "125574      135           NaN        188     False  \n",
       "125602      135            21        188     False  \n",
       "125923      135            20        188     False  \n",
       "125727      135            18        188     False  \n",
       "125756      135            15        188     False  \n",
       "125786      135            14        188     False  \n",
       "125939      135            12        188     False  \n",
       "126303      135            10        188     False  \n",
       "126332      135             9        188     False  \n",
       "126390      135             7        188     False  \n",
       "126443      135             3        188     False  \n",
       "126501      135             3        188     False  \n",
       "126544      135             1        188     False  \n",
       "126570      135             0        188     False  \n",
       "126599      135            -1        188     False  \n",
       "126733      135             0        188     False  \n",
       "126752      135             2        188     False  \n",
       "126782      135             5        188     False  \n",
       "126810      135             9        188     False  \n",
       "126934      135            11        188     False  \n",
       "126962      135            12        188     False  \n",
       "126990      135            14        188     False  \n",
       "127018      135            15        188     False  \n",
       "127141      135            15        188     False  \n",
       "127168      135            15        188     False  \n",
       "127290      135            15        188     False  \n",
       "127319      135            15        188     False  \n",
       "127347      135            14        188     False  \n",
       "\n",
       "[1379 rows x 9 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sensors.user_id.value_counts()\n",
    "#sensordata.violation.value_counts() #This returns the number of 't's and 'f's\n",
    "#np.sort(userdata.id.unique())\n",
    "#np.intersect1d(userdata.id.unique(), sensordata.user_id.unique()) #Returns the common ids in both the datasets.\n",
    "#readings.sensor_id.unique\n",
    "\n",
    "users.loc[users.last_name == \"Quashie\"]\n",
    "#users.loc[users.id==160]\n",
    "readings.loc[readings.user_id == 135].sort_values('created_at')\n",
    "#users.loc[users.id == 236]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
